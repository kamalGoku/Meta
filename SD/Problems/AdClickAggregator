* Function Req
* Non-Functional Req
  - ask about the scale, like 10M AU and 10K clicks/sec
* Data Flow
* HLD
  - user, ad placement service and Click Processing Service
  - User clicks and gets click service, gives the redirect URL, ensures to capture the click

  - Good Sol: Use write heavy DB(Cassandra) for capturing the clicks
     - Use Spark(data aggregator) with a cron job every 5 min to aggregate data and store in OLAP
     - Advertisers will read data using an analytics service from OLAP
     - OLAP can handle multidimensional data for querying
 - Great Sol: Use Kinesis and Flink for data processing.
     - Click data is captured by Kinesis and FLink aggregates them
     - Once the time window is reached, Flink sends the data to OLAP
     - In Flink, we can tune to aggregate and send data every 10s, but in Spark, we can't do that.
     - Real-time aggregation is possible with Flink

* Deep Dives
  - How to scale 10K clicks/sec?
    - Have horizontal scaling in Click processing Service, Flink, OLAP
    - Since Kinesis supports 1000 req/s, shard it based on AdId, so each shard has 1000 req/s
    - Hot shards
      - Distribute to different shards with random number(0...N), N-additonal partition req for AdId.
      - By this way, the throttling is secured, but we need to adjust Flink to ignore this random number during agg.
  - How can we ensure our data is not lost?
    - Kinesis is already distributed and hence they are highly available, fault-tolerant
    - We can have a 7-day retention period for Kinesis
    - Having Checkpoint is not a good solution
    - We can store the raw click events in S3 and run Spark on that data every hour/day. Reconcile the batch process output to OLAP.
      This hybrid method of Kinesis + Spark ensures the analytics are fast and correct
  - How can we prevent abuse from users? How to achieve idempotency?
    - AdPlacement Service generates all with an impression ID
    - When a user clicks the ad, the click data is sent with the impression ID., click service checks the signature of the impression ID, and if valid it puts in the  Redis cache
    - If the impression ID is already present, then the click is not added to Kinesis, else we do
    - We are having the fingerprint here to check if any malicious user is mimicking the impression ID.
    - The cache can be scaled and is fault-tolerant
  - How can we ensure advertiser gets the metrics with low latency?
    - we use OLAP which agfregates the data
    - we can agregate for days, month and year for its fast access
